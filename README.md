# ğŸš Aerial Forensics: The Searchlight Protocol ğŸ”¦

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![YOLOv8](https://img.shields.io/badge/YOLO-v8-00FFFF?style=for-the-badge&logo=yolo&logoColor=black)
![Status](https://img.shields.io/badge/Status-Research_Prototype-orange?style=for-the-badge)

> **"Finding the needle in the haystack, from 400ft above."**

**The Searchlight Protocol** is a coarse-to-fine computer vision pipeline designed for efficient small object detection in high-resolution (2K/4K) aerial imagery. It addresses the critical trade-off between resolution and latency in drone forensics.

Unlike "blind" sliding window approaches (e.g., SAHI) that process empty backgrounds (sky, grass) with the same cost as targets, this system uses **LayerCAM (Class Activation Mapping)** to identify semantic "hotspots" first. It then intelligently slices and zooms into these regions for high-precision detection, eliminating background noise without sacrificing recall.

---

## ğŸ“‰ The Problem: Why Standard Models Fail

When detecting small objects (humans, animals) in drone footage, standard methods face two failures :

| Method | The Failure Mode |
| :--- | :--- |
| **Standard YOLO (Resized)** | Resizing a 4K image to 640x640 destroys small features. Objects like pedestrians become <1 pixel and vanish. |
| **SAHI (Blind Slicing)** | Cuts the image into a fixed grid (e.g., 20 slices). It is accurate but computationally wasteful, processing empty forests/oceans unnecessarily. |
| **The Searchlight (Ours)** | **Smart Slicing.** Only processes regions where the "Guide" (ResNet50) detects semantic activity. |

---

## ğŸ§  Methodology: The 3-Stage Pipeline

The system implements a novel "Search & Stare" architecture:

<p align="center">
  <img src="Images/Architectural Diagram.png" alt="The Searchlight Protocol Pipeline Architecture" width="100%"/>
  <br/>
  <sub><i>ğŸ¨ Diagram generated with Gemini</i></sub>
</p>

### 1. Stage 1: The Guide (Global Context) 
- **Backbone**: ResNet-50 (Pretrained).
- **Technique**: Generates a **LayerCAM** saliency map from the deep convolutional layers (Layer 3/4).
- **Output**: A heatmap highlighting "anomalous" regions (potential targets) irrespective of their specific class.

### 2. Stage 2: The Intelligent Slicer 
- **Dynamic Cropping**: Instead of a fixed grid, the slicer contours the heatmap blobs.
- **Context Padding**: Adds **30-40% context padding** around blobs to ensure objects aren't cut in half.
- **Filtering**: Ignores low-activation areas (e.g., empty roads, dense canopy).

### 3. Stage 3: The Detector 
- **Model**: YOLOv8/v9 (Medium).
- **Inference**: Runs *only* on the crops generated by Stage 2.
- **Fusion**: Maps local crop coordinates back to the global 4K frame for the final output.

---

## ğŸ“Š Performance & Comparison

*Based on preliminary benchmarks against YOLOv8-Medium and SAHI.*

| Metric | Standard YOLOv8 | SAHI (Blind Slicing) | Searchlight (Ours) |
| :--- | :--- | :--- | :--- |
| **Small Object Recall** | âŒ Fails (Objects Vanish) | âœ… High | âœ… High |
| **Efficiency** | âš¡ Fastest | ğŸ¢ Slow (Processes Everything) | ğŸš€ **Efficient** (Skips Background) |
| **False Positives** | Low | âš ï¸ High (Hallucinations) | âœ… Low (Context Aware) |

> **Case Study:** In tests containing small biological targets (e.g., Elephants), standard YOLO detected **0 objects**. SAHI detected **12 objects**, but many were hallucinations (labeled "broccoli" or "boot"). The Searchlight Protocol correctly identified the targets with high confidence.

---

## ğŸ–¼ï¸ Results Gallery

Sample outputs from the pipeline showing the complete detection workflow:

<details>
<summary><b>ğŸ”¬ Example 1: Elephant Detection (DPP_00444)</b></summary>
<br/>
<p align="center">
  <img src="Images/Output_1.jpg" alt="Searchlight Protocol Results - Elephant Detection" width="100%"/>
</p>
<i>The pipeline successfully detects elephants in savannah terrain. Top-left: Input image. Top-right: LayerCAM heatmap showing semantic hotspots. Bottom-left: Post-NMS bounding boxes from intelligent slicing. Bottom-right: Final YOLO detections with confidence scores.</i>
</details>

<details>
<summary><b>ğŸ”¬ Example 2: Multi-Target Detection (DPP_00464)</b></summary>
<br/>
<p align="center">
  <img src="Images/Output_2.jpg" alt="Searchlight Protocol Results - Multi-Target Detection" width="100%"/>
</p>
<i>Dense scene with multiple wildlife targets. The intelligent slicer generates numerous crops from heatmap hotspots, enabling YOLO to detect sheep, elephants, and other animals that would be invisible at standard resolution.</i>
</details>

<details>
<summary><b>ğŸ”¬ Example 3: Wildlife Conservation (DPP_00465)</b></summary>
<br/>
<p align="center">
  <img src="Images/Output_3.jpg" alt="Searchlight Protocol Results - Wildlife Conservation" width="100%"/>
</p>
<i>Demonstration of high-confidence detections across varying terrain. The context-aware cropping ensures full animal bodies are captured, improving classification accuracy.</i>
</details>

---

## ğŸŒ Real-World Applications

This pipeline is optimized for edge-case scenarios where bandwidth and compute are limited :
- **ğŸš‘ Search and Rescue (SAR)**: Finding lost hikers in dense terrain without processing miles of empty forest.
- **ğŸŒªï¸ Disaster Response**: Rapid damage assessment of rooftops after floods/earthquakes.
- **ğŸ˜ Wildlife Conservation**: Counting herds in savannahs where animals are camouflaged against the ground.
- **ğŸ›¡ï¸ Border Security**: Detecting vehicles/troops in remote areas with low-bandwidth transmission.

---

## ğŸ“‚ Project Structure

| File | Description |
| :--- | :--- |
| `The_searchlight_Protocol.ipynb` | ğŸ““ **Main Notebook**. Runs the full pipeline: Load -> Search -> Slice -> Detect. |
| `Detector.py` | ğŸ•µï¸ **YOLO Wrapper**. Manages the Ultralytics YOLOv8/v9 model instance. |
| `LayerCam.py` | ğŸ—ºï¸ **Attention Engine**. Custom implementation to extract gradients from ResNet layers. |
| `Slicer.py` | ğŸ”ª **Smart Slicer**. Contours heatmaps and applies dynamic padding logic. |
| `ImageLoader.py` | ğŸ—ï¸ **I/O Utility**. Handles massive TIFF/JPG files with contrast enhancement. |
| `requirements.txt` | ğŸ“¦ Dependencies (Torch, OpenCV, Ultralytics). |

---



## ğŸ› ï¸ Roadmap

- [x] **Core Pipeline**: ResNet Guide + YOLO Detector
- [x] **Intelligent Slicing**: Dynamic padding & contouring
- [ ] **Temporal Consistency**: Adding object tracking for video streams.
- [ ] **Edge Deployment**: Porting to NVIDIA Jetson / Raspberry Pi.

---
