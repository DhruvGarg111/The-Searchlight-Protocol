# ğŸš Drone Forensics: The Searchlight Protocol ğŸ”¦

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![YOLOv8](https://img.shields.io/badge/YOLO-v8-00FFFF?style=for-the-badge&logo=yolo&logoColor=black)
![Status](https://img.shields.io/badge/Status-Research_Prototype-orange?style=for-the-badge)

> **"Finding the needle in the haystack, from 400ft above."**

**The Searchlight Protocol** is a coarse-to-fine computer vision pipeline designed for efficient small object detection in high-resolution (2K/4K) aerial imagery. It addresses the critical trade-off between resolution and latency in drone forensics.

Unlike "blind" sliding window approaches (e.g., SAHI) that process empty backgrounds (sky, grass) with the same cost as targets, this system uses **LayerCAM (Class Activation Mapping)** to identify semantic "hotspots" first. It then intelligently slices and zooms into these regions for high-precision detection, eliminating background noise without sacrificing recall.

---

## ğŸ“‰ The Problem: Why Standard Models Fail

When detecting small objects (humans, animals) in drone footage, standard methods face two failures :

| Method | The Failure Mode |
| :--- | :--- |
| **Standard YOLO (Resized)** | Resizing a 4K image to 640x640 destroys small features. Objects like pedestrians become <1 pixel and vanish. |
| **SAHI (Blind Slicing)** | Cuts the image into a fixed grid (e.g., 20 slices). It is accurate but computationally wasteful, processing empty forests/oceans unnecessarily. |
| **The Searchlight (Ours)** | **Smart Slicing.** Only processes regions where the "Guide" (ResNet50) detects semantic activity. |

---

## ğŸ§  Methodology: The 3-Stage Pipeline

The system implements a novel "Search & Stare" architecture :

### 1. Stage 1: The Guide (Global Context) 
- **Backbone**: ResNet-50 (Pretrained).
- **Technique**: Generates a **LayerCAM** saliency map from the deep convolutional layers (Layer 3/4) .
- **Output**: A heatmap highlighting "anomalous" regions (potential targets) irrespective of their specific class.

### 2. Stage 2: The Intelligent Slicer 
- **Dynamic Cropping**: Instead of a fixed grid, the slicer contours the heatmap blobs.
- **Context Padding**: Adds **30-40% context padding** around blobs to ensure objects aren't cut in half.
- **Filtering**: Ignores low-activation areas (e.g., empty roads, dense canopy).

### 3. Stage 3: The Detector 
- **Model**: YOLOv8/v9 (Medium).
- **Inference**: Runs *only* on the crops generated by Stage 2.
- **Fusion**: Maps local crop coordinates back to the global 4K frame for the final output.

---

## ğŸ“Š Performance & Comparison

*Based on preliminary benchmarks against YOLOv8-Medium and SAHI.*

| Metric | Standard YOLOv8 | SAHI (Blind Slicing) | Searchlight (Ours) |
| :--- | :--- | :--- | :--- |
| **Small Object Recall** | âŒ Fails (Objects Vanish) | âœ… High | âœ… High |
| **Efficiency** | âš¡ Fastest | ğŸ¢ Slow (Processes Everything) | ğŸš€ **Efficient** (Skips Background) |
| **False Positives** | Low | âš ï¸ High (Hallucinations) | âœ… Low (Context Aware) |

> **Case Study:** In tests containing small biological targets (e.g., Elephants), standard YOLO detected **0 objects**. SAHI detected **12 objects**, but many were hallucinations (labeled "broccoli" or "boot"). The Searchlight Protocol correctly identified the targets with high confidence .

---

## ğŸŒ Real-World Applications

This pipeline is optimized for edge-case scenarios where bandwidth and compute are limited :
- **ğŸš‘ Search and Rescue (SAR)**: Finding lost hikers in dense terrain without processing miles of empty forest.
- **ğŸŒªï¸ Disaster Response**: Rapid damage assessment of rooftops after floods/earthquakes.
- **ğŸ˜ Wildlife Conservation**: Counting herds in savannahs where animals are camouflaged against the ground.
- **ğŸ›¡ï¸ Border Security**: Detecting vehicles/troops in remote areas with low-bandwidth transmission.

---

## ğŸ“‚ Project Structure

| File | Description |
| :--- | :--- |
| `The_searchlight_Protocol.ipynb` | ğŸ““ **Main Notebook**. Runs the full pipeline: Load -> Search -> Slice -> Detect. |
| `Detector.py` | ğŸ•µï¸ **YOLO Wrapper**. Manages the Ultralytics YOLOv8/v9 model instance. |
| `LayerCam.py` | ğŸ—ºï¸ **Attention Engine**. Custom implementation to extract gradients from ResNet layers. |
| `Slicer.py` | ğŸ”ª **Smart Slicer**. Contours heatmaps and applies dynamic padding logic. |
| `ImageLoader.py` | ğŸ—ï¸ **I/O Utility**. Handles massive TIFF/JPG files with contrast enhancement. |
| `requirements.txt` | ğŸ“¦ Dependencies (Torch, OpenCV, Ultralytics). |

---



## ğŸ› ï¸ Roadmap

- [x] **Core Pipeline**: ResNet Guide + YOLO Detector
- [x] **Intelligent Slicing**: Dynamic padding & contouring
- [ ] **Temporal Consistency**: Adding object tracking for video streams.
- [ ] **Edge Deployment**: Porting to NVIDIA Jetson / Raspberry Pi.

---
